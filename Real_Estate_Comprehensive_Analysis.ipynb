{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Comprehensive Real Estate Data Analysis\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook provides a complete end-to-end analysis of real estate data using advanced statistical methods, machine learning, and interactive visualizations.\n",
    "\n",
    "**Key Features:**\n",
    "- Secure PostgreSQL database integration\n",
    "- Comprehensive exploratory data analysis\n",
    "- Interactive visualizations and geographic mapping\n",
    "- Statistical hypothesis testing\n",
    "- Machine learning predictive modeling\n",
    "- Market analysis and investment insights\n",
    "- Automated reporting and recommendations\n",
    "\n",
    "---\n",
    "\n",
    "**Data Sources**: RentCast, RentSpider, Demo APIs  \n",
    "**Database**: PostgreSQL with real estate pipeline data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup & Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Data Analysis Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database Libraries\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "\n",
    "# Statistical Analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Advanced libraries (optional)\n",
    "try:\n",
    "    import folium\n",
    "    from folium.plugins import HeatMap, MarkerCluster\n",
    "    GEO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Folium not available. Geographic visualizations will be limited.\")\n",
    "    GEO_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    import shap\n",
    "    ADVANCED_ML = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Advanced ML libraries not available. Basic ML models will be used.\")\n",
    "    ADVANCED_ML = False\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìä Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Connection Class\n",
    "class DatabaseConnector:\n",
    "    def __init__(self):\n",
    "        self.engine = None\n",
    "        \n",
    "    def connect(self, connection_string: str = None):\n",
    "        try:\n",
    "            if not connection_string:\n",
    "                connection_string = os.getenv(\n",
    "                    'DATABASE_URL', \n",
    "                    'postgresql://postgres:password@localhost:5432/real_estate_db'\n",
    "                )\n",
    "            \n",
    "            self.engine = create_engine(\n",
    "                connection_string,\n",
    "                pool_size=10,\n",
    "                max_overflow=20,\n",
    "                pool_pre_ping=True\n",
    "            )\n",
    "            \n",
    "            with self.engine.connect() as conn:\n",
    "                conn.execute(text(\"SELECT 1\"))\n",
    "                print(\"‚úÖ Database connection successful\")\n",
    "                \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Database connection failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_data(self, query: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            return pd.read_sql(query, self.engine)\n",
    "        except Exception as e:\n",
    "            print(f\"Query failed: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# Initialize database connection\n",
    "db = DatabaseConnector()\n",
    "connection_success = db.connect()\n",
    "\n",
    "if connection_success:\n",
    "    display(HTML(\"<div style='background-color: #d4edda; padding: 10px; border-radius: 5px;'><strong>‚úÖ Database Status:</strong> Connected and Ready</div>\"))\n",
    "else:\n",
    "    display(HTML(\"<div style='background-color: #f8d7da; padding: 10px; border-radius: 5px;'><strong>‚ùå Database Status:</strong> Connection Failed</div>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Extraction & Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract property data\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id, address, city, state, zip_code,\n",
    "    latitude, longitude, property_type,\n",
    "    bedrooms, bathrooms, square_feet, lot_size,\n",
    "    year_built, current_price, listing_status,\n",
    "    created_at, updated_at\n",
    "FROM properties \n",
    "ORDER BY created_at DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîÑ Loading property data...\")\n",
    "properties_df = db.get_data(query)\n",
    "\n",
    "if not properties_df.empty:\n",
    "    print(f\"‚úÖ Loaded {len(properties_df):,} properties\")\n",
    "    \n",
    "    # Display basic info\n",
    "    print(f\"\\nüìä Dataset Overview:\")\n",
    "    print(f\"   Shape: {properties_df.shape}\")\n",
    "    print(f\"   Memory: {properties_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    print(f\"   Date range: {properties_df['created_at'].min()} to {properties_df['created_at'].max()}\")\n",
    "    \n",
    "    # Preview data\n",
    "    print(\"\\nüîç Data Preview:\")\n",
    "    display(properties_df.head())\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data loaded. Please check database connection and data availability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Assessment\n",
    "if not properties_df.empty:\n",
    "    print(\"üìã Data Quality Assessment:\")\n",
    "    \n",
    "    # Missing data analysis\n",
    "    missing_data = properties_df.isnull().sum()\n",
    "    missing_pct = (missing_data / len(properties_df)) * 100\n",
    "    \n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Missing_Count': missing_data,\n",
    "        'Missing_Percentage': missing_pct.round(1)\n",
    "    })\n",
    "    missing_summary = missing_summary[missing_summary['Missing_Count'] > 0]\n",
    "    \n",
    "    if not missing_summary.empty:\n",
    "        print(\"\\n‚ùì Missing Data Summary:\")\n",
    "        display(missing_summary.sort_values('Missing_Count', ascending=False))\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No missing data found!\")\n",
    "    \n",
    "    # Data types and basic stats\n",
    "    print(\"\\nüìà Numeric Data Summary:\")\n",
    "    numeric_cols = properties_df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        display(properties_df[numeric_cols].describe())\n",
    "    \n",
    "    # Categorical data summary\n",
    "    print(\"\\nüè∑Ô∏è Categorical Data Summary:\")\n",
    "    categorical_cols = ['city', 'state', 'property_type', 'listing_status']\n",
    "    for col in categorical_cols:\n",
    "        if col in properties_df.columns:\n",
    "            unique_count = properties_df[col].nunique()\n",
    "            print(f\"   {col}: {unique_count} unique values\")\n",
    "            if unique_count <= 10:\n",
    "                print(f\"      {list(properties_df[col].value_counts().head().index)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for quality assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Market Insights\n",
    "if not properties_df.empty:\n",
    "    print(\"üîç Key Market Insights:\")\n",
    "    \n",
    "    # Price analysis\n",
    "    if 'current_price' in properties_df.columns:\n",
    "        price_data = properties_df['current_price'].dropna()\n",
    "        if len(price_data) > 0:\n",
    "            print(f\"\\nüí∞ Price Analysis:\")\n",
    "            print(f\"   Range: ${price_data.min():,.0f} - ${price_data.max():,.0f}\")\n",
    "            print(f\"   Average: ${price_data.mean():,.0f}\")\n",
    "            print(f\"   Median: ${price_data.median():,.0f}\")\n",
    "            print(f\"   Standard Deviation: ${price_data.std():,.0f}\")\n",
    "    \n",
    "    # Geographic distribution\n",
    "    if 'city' in properties_df.columns:\n",
    "        city_counts = properties_df['city'].value_counts()\n",
    "        print(f\"\\nüèôÔ∏è Geographic Distribution:\")\n",
    "        print(f\"   Total Cities: {len(city_counts)}\")\n",
    "        print(f\"   Top 5 Cities:\")\n",
    "        for city, count in city_counts.head().items():\n",
    "            print(f\"     {city}: {count} properties\")\n",
    "    \n",
    "    # Property type distribution\n",
    "    if 'property_type' in properties_df.columns:\n",
    "        type_counts = properties_df['property_type'].value_counts()\n",
    "        print(f\"\\nüè† Property Type Distribution:\")\n",
    "        for prop_type, count in type_counts.items():\n",
    "            pct = (count / len(properties_df)) * 100\n",
    "            print(f\"   {prop_type}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Size analysis\n",
    "    if 'square_feet' in properties_df.columns:\n",
    "        size_data = properties_df['square_feet'].dropna()\n",
    "        if len(size_data) > 0:\n",
    "            print(f\"\\nüìê Size Analysis:\")\n",
    "            print(f\"   Average Size: {size_data.mean():,.0f} sq ft\")\n",
    "            print(f\"   Median Size: {size_data.median():,.0f} sq ft\")\n",
    "            print(f\"   Size Range: {size_data.min():,.0f} - {size_data.max():,.0f} sq ft\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Distribution Visualization\n",
    "if not properties_df.empty and 'current_price' in properties_df.columns:\n",
    "    price_data = properties_df['current_price'].dropna()\n",
    "    \n",
    "    if len(price_data) > 0:\n",
    "        # Price histogram\n",
    "        fig = px.histogram(\n",
    "            properties_df.dropna(subset=['current_price']), \n",
    "            x='current_price', \n",
    "            nbins=50,\n",
    "            title='Property Price Distribution',\n",
    "            labels={'current_price': 'Price ($)', 'count': 'Number of Properties'}\n",
    "        )\n",
    "        fig.update_layout(height=400)\n",
    "        fig.show()\n",
    "        \n",
    "        # Property type distribution\n",
    "        if 'property_type' in properties_df.columns:\n",
    "            type_counts = properties_df['property_type'].value_counts()\n",
    "            fig = px.pie(\n",
    "                values=type_counts.values,\n",
    "                names=type_counts.index,\n",
    "                title='Property Type Distribution'\n",
    "            )\n",
    "            fig.update_layout(height=400)\n",
    "            fig.show()\n",
    "        \n",
    "        # Price vs Size scatter plot\n",
    "        if 'square_feet' in properties_df.columns:\n",
    "            scatter_data = properties_df[['current_price', 'square_feet', 'property_type']].dropna()\n",
    "            if len(scatter_data) > 0:\n",
    "                fig = px.scatter(\n",
    "                    scatter_data,\n",
    "                    x='square_feet',\n",
    "                    y='current_price',\n",
    "                    color='property_type',\n",
    "                    title='Price vs Square Feet by Property Type',\n",
    "                    labels={'square_feet': 'Square Feet', 'current_price': 'Price ($)'},\n",
    "                    trendline='ols'\n",
    "                )\n",
    "                fig.update_layout(height=500)\n",
    "                fig.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No price data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic Visualization\n",
    "if not properties_df.empty and 'latitude' in properties_df.columns and 'longitude' in properties_df.columns:\n",
    "    geo_data = properties_df[['latitude', 'longitude', 'current_price', 'city', 'property_type']].dropna()\n",
    "    \n",
    "    if len(geo_data) > 0:\n",
    "        print(f\"üó∫Ô∏è Creating geographic visualization for {len(geo_data)} properties...\")\n",
    "        \n",
    "        # Interactive map with Plotly\n",
    "        fig = px.scatter_mapbox(\n",
    "            geo_data,\n",
    "            lat='latitude',\n",
    "            lon='longitude',\n",
    "            color='current_price',\n",
    "            size='current_price',\n",
    "            hover_data=['city', 'property_type'],\n",
    "            title='Property Locations by Price',\n",
    "            mapbox_style='open-street-map',\n",
    "            height=600,\n",
    "            color_continuous_scale='Viridis'\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        # City-wise price comparison\n",
    "        if 'city' in properties_df.columns:\n",
    "            city_price = properties_df.groupby('city')['current_price'].agg(['mean', 'count']).reset_index()\n",
    "            city_price = city_price[city_price['count'] >= 5]  # Cities with at least 5 properties\n",
    "            \n",
    "            if len(city_price) > 0:\n",
    "                fig = px.bar(\n",
    "                    city_price.sort_values('mean', ascending=False).head(10),\n",
    "                    x='city',\n",
    "                    y='mean',\n",
    "                    title='Average Property Price by City (Top 10)',\n",
    "                    labels={'mean': 'Average Price ($)', 'city': 'City'}\n",
    "                )\n",
    "                fig.update_layout(height=400, xaxis_tickangle=-45)\n",
    "                fig.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No geographic data available for mapping\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No coordinate data available for geographic visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "if not properties_df.empty:\n",
    "    print(\"üìä Statistical Analysis:\")\n",
    "    \n",
    "    # Select numeric columns for correlation\n",
    "    numeric_cols = properties_df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    if len(numeric_cols) > 1:\n",
    "        print(\"\\nüîó Correlation Analysis:\")\n",
    "        corr_matrix = properties_df[numeric_cols].corr()\n",
    "        \n",
    "        # Create correlation heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "                   square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "        plt.title('Correlation Matrix of Numeric Variables')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Strongest correlations with price\n",
    "        if 'current_price' in corr_matrix.columns:\n",
    "            price_corr = corr_matrix['current_price'].abs().sort_values(ascending=False)\n",
    "            price_corr = price_corr[price_corr.index != 'current_price']\n",
    "            \n",
    "            print(\"\\nüí∞ Variables most correlated with price:\")\n",
    "            for var, corr in price_corr.head(5).items():\n",
    "                direction = \"positive\" if corr_matrix.loc[var, 'current_price'] > 0 else \"negative\"\n",
    "                print(f\"   {var}: {corr:.3f} ({direction})\")\n",
    "    \n",
    "    # Statistical Tests\n",
    "    print(\"\\nüß™ Hypothesis Testing:\")\n",
    "    \n",
    "    # Test 1: Price differences by property type\n",
    "    if 'property_type' in properties_df.columns and 'current_price' in properties_df.columns:\n",
    "        price_by_type = []\n",
    "        types = properties_df['property_type'].dropna().unique()\n",
    "        \n",
    "        for prop_type in types:\n",
    "            prices = properties_df[properties_df['property_type'] == prop_type]['current_price'].dropna()\n",
    "            if len(prices) >= 3:  # Need at least 3 observations\n",
    "                price_by_type.append(prices)\n",
    "        \n",
    "        if len(price_by_type) >= 2:\n",
    "            try:\n",
    "                f_stat, p_value = stats.f_oneway(*price_by_type)\n",
    "                print(f\"\\n   ANOVA Test (Price by Property Type):\")\n",
    "                print(f\"   F-statistic: {f_stat:.3f}\")\n",
    "                print(f\"   P-value: {p_value:.3f}\")\n",
    "                \n",
    "                if p_value < 0.05:\n",
    "                    print(f\"   ‚úÖ Significant price differences between property types (p < 0.05)\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå No significant price differences between property types (p ‚â• 0.05)\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Could not perform ANOVA: {e}\")\n",
    "    \n",
    "    # Test 2: Correlation between price and size\n",
    "    if 'current_price' in properties_df.columns and 'square_feet' in properties_df.columns:\n",
    "        price_size_data = properties_df[['current_price', 'square_feet']].dropna()\n",
    "        \n",
    "        if len(price_size_data) >= 10:\n",
    "            try:\n",
    "                corr_coef, p_value = pearsonr(price_size_data['current_price'], price_size_data['square_feet'])\n",
    "                print(f\"\\n   Correlation Test (Price vs Size):\")\n",
    "                print(f\"   Correlation coefficient: {corr_coef:.3f}\")\n",
    "                print(f\"   P-value: {p_value:.3f}\")\n",
    "                \n",
    "                if p_value < 0.05:\n",
    "                    strength = \"strong\" if abs(corr_coef) > 0.7 else \"moderate\" if abs(corr_coef) > 0.3 else \"weak\"\n",
    "                    direction = \"positive\" if corr_coef > 0 else \"negative\"\n",
    "                    print(f\"   ‚úÖ Significant {strength} {direction} correlation (p < 0.05)\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå No significant correlation (p ‚â• 0.05)\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Could not calculate correlation: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for statistical analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Machine Learning & Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning for Price Prediction\n",
    "if not properties_df.empty:\n",
    "    print(\"ü§ñ Machine Learning Analysis:\")\n",
    "    \n",
    "    # Define features for prediction\n",
    "    feature_cols = ['bedrooms', 'bathrooms', 'square_feet', 'lot_size', 'year_built']\n",
    "    available_features = [col for col in feature_cols if col in properties_df.columns]\n",
    "    \n",
    "    if len(available_features) >= 2 and 'current_price' in properties_df.columns:\n",
    "        # Prepare ML dataset\n",
    "        ml_data = properties_df[available_features + ['current_price']].dropna()\n",
    "        \n",
    "        print(f\"\\nüìä ML Dataset: {len(ml_data)} properties with complete data\")\n",
    "        print(f\"   Features: {available_features}\")\n",
    "        \n",
    "        if len(ml_data) >= 50:\n",
    "            X = ml_data[available_features]\n",
    "            y = ml_data['current_price']\n",
    "            \n",
    "            # Train-test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            print(f\"   Training set: {len(X_train)} properties\")\n",
    "            print(f\"   Test set: {len(X_test)} properties\")\n",
    "            \n",
    "            # Train multiple models\n",
    "            models = {\n",
    "                'Linear Regression': LinearRegression(),\n",
    "                'Ridge Regression': Ridge(alpha=1.0),\n",
    "                'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            }\n",
    "            \n",
    "            results = {}\n",
    "            \n",
    "            print(\"\\nüéØ Model Training Results:\")\n",
    "            \n",
    "            for name, model in models.items():\n",
    "                try:\n",
    "                    # Train model\n",
    "                    model.fit(X_train, y_train)\n",
    "                    \n",
    "                    # Make predictions\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    r2 = r2_score(y_test, y_pred)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                    mae = mean_absolute_error(y_test, y_pred)\n",
    "                    \n",
    "                    results[name] = {\n",
    "                        'R¬≤ Score': r2,\n",
    "                        'RMSE': rmse,\n",
    "                        'MAE': mae\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"\\n   {name}:\")\n",
    "                    print(f\"     R¬≤ Score: {r2:.4f} ({r2*100:.1f}% of variance explained)\")\n",
    "                    print(f\"     RMSE: ${rmse:,.0f}\")\n",
    "                    print(f\"     MAE: ${mae:,.0f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ö†Ô∏è Error training {name}: {e}\")\n",
    "            \n",
    "            # Feature importance for Random Forest\n",
    "            if 'Random Forest' in results and 'Random Forest' in models:\n",
    "                try:\n",
    "                    rf_model = models['Random Forest']\n",
    "                    importance_df = pd.DataFrame({\n",
    "                        'Feature': available_features,\n",
    "                        'Importance': rf_model.feature_importances_\n",
    "                    }).sort_values('Importance', ascending=False)\n",
    "                    \n",
    "                    print(\"\\nüéØ Feature Importance (Random Forest):\")\n",
    "